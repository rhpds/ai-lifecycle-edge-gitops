{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf730312",
   "metadata": {},
   "source": [
    "# 07 - Upload Models to S3 Storage\n",
    "\n",
    "This notebook uploads the trained models and their scalers to an S3-compatible object storage service, making them available for deployment and serving in production environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200c4ad1",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "Import boto3 for S3 operations and os for environment variable access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aa598c0-5ce6-417a-95f1-e4faec1d7505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c922625e",
   "metadata": {},
   "source": [
    "## Load S3 Configuration from Environment\n",
    "\n",
    "Retrieve AWS S3 credentials and endpoint information from environment variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9125246e-91f2-481e-8aa7-cd3e89693eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "secret_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "endpoint = os.getenv(\"AWS_S3_ENDPOINT\")\n",
    "bucket_name = os.getenv(\"AWS_S3_BUCKET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6703a1",
   "metadata": {},
   "source": [
    "## Create S3 Client\n",
    "\n",
    "Initialize the boto3 S3 client with the configured credentials and endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaaf7d0d-809e-4a36-8388-456c1ebd2794",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=key_id,\n",
    "    aws_secret_access_key=secret_key,\n",
    "    endpoint_url=endpoint,\n",
    "    use_ssl=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f132a88",
   "metadata": {},
   "source": [
    "## Upload Stress Detection Model\n",
    "\n",
    "Define a function to recursively upload directory contents to S3, then upload the stress detection model files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e169ee-538d-4c0c-8271-b44620d797ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_path = 'models/serving/battery_stress_model'\n",
    "s3_prefix = 'models/serving/battery_stress_model'\n",
    "\n",
    "def upload_directory_to_s3(local_path, bucket, s3_prefix):\n",
    "    uploaded_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(local_path):\n",
    "        for file in files:\n",
    "            local_file = os.path.join(root, file)\n",
    "            relative_path = os.path.relpath(local_file, local_path)\n",
    "            s3_key = os.path.join(s3_prefix, relative_path).replace('\\\\', '/')\n",
    "            \n",
    "            s3_client.upload_file(local_file, bucket, s3_key)\n",
    "            uploaded_files.append(s3_key)\n",
    "    \n",
    "    return uploaded_files\n",
    "\n",
    "uploaded = upload_directory_to_s3(local_model_path, bucket_name, s3_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87131594",
   "metadata": {},
   "source": [
    "## Upload Stress Model Scaler\n",
    "\n",
    "Upload the StandardScaler used for the stress detection model to ensure consistent data preprocessing during inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e06c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_local_path = 'models/stress_scaler.pkl'\n",
    "scaler_s3_key = 'models/serving/battery_stress_model/scaler.pkl'\n",
    "\n",
    "if os.path.exists(scaler_local_path):\n",
    "    s3_client.upload_file(scaler_local_path, bucket_name, scaler_s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67323c05",
   "metadata": {},
   "source": [
    "## Upload Time-to-Failure Model and Scaler\n",
    "\n",
    "Upload the TTF model files and its corresponding scaler to S3 storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "339f4829-9022-4bc7-85ee-33decf1f999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_ttf_model_path = 'models/serving/battery_ttf_model'\n",
    "s3_ttf_prefix = 'models/serving/battery_ttf_model'\n",
    "\n",
    "uploaded_ttf = upload_directory_to_s3(local_ttf_model_path, bucket_name, s3_ttf_prefix)\n",
    "\n",
    "ttf_scaler_local_path = 'models/ttf_scaler.pkl'\n",
    "ttf_scaler_s3_key = 'models/serving/battery_ttf_model/ttf_scaler.pkl'\n",
    "\n",
    "if os.path.exists(ttf_scaler_local_path):\n",
    "    s3_client.upload_file(ttf_scaler_local_path, bucket_name, ttf_scaler_s3_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
